[{"authors":["admin"],"categories":null,"content":"Hi folks, my name is Carlos and I\u0026rsquo;m R, bioinformatics and single-cell enthusiast! Since 2012, I have been working with microarray and RNA-seq data, but things started to get more intense when, in 2017, I started my PhD at the University of SÃ£o Paulo in Department of Genetics in RibeirÃ£o Preto Medica School. Since then I have been dedicating myself to single-cell analysis.\nI\u0026rsquo;m currently as PhD Researcher Assistant at the UniversitÃ¤t zu KÃ¶ln working in Prof. Martin Peifer lab in the Department of Translational Genomics.\nI have always kept in mind that good science is science that can be reproduced and shared. Based on this principle, I decided to create this blog to share good and bad experiences that I had and I am having during this journey as a bioinformatician. The main idea is to share solutions I found for the problems I had. I sincerely hope that this blog can help other people and also that it is a means of new connections with people in the bioinformatics field.\nMay the force be with you!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://cbiagii.github.io/author/carlos-biagi-jr/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/carlos-biagi-jr/","section":"authors","summary":"Hi folks, my name is Carlos and I\u0026rsquo;m R, bioinformatics and single-cell enthusiast! Since 2012, I have been working with microarray and RNA-seq data, but things started to get more intense when, in 2017, I started my PhD at the University of SÃ£o Paulo in Department of Genetics in RibeirÃ£o Preto Medica School.","tags":null,"title":"Carlos Biagi Jr","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://cbiagii.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Publications","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://cbiagii.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://cbiagii.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":[],"content":"","date":1596971320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596971320,"objectID":"d6a2cd759885b31f71332fe1e801f2e6","permalink":"https://cbiagii.github.io/project/cetf/","publishdate":"2020-08-09T13:08:40+02:00","relpermalink":"/project/cetf/","section":"project","summary":"This package provides the necessary functions for performing the Partial Correlation coefficient with Information Theory (PCIT) (Reverter and Chan 2008) and Regulatory Impact Factors (RIF) (Reverter et al. 2010) algorithm. The PCIT algorithm identifies meaningful correlations to define edges in a weighted network and can be applied to any correlation-based network including but not limited to gene co-expression networks, while the RIF algorithm identify critical Transcription Factors (TF) from gene expression data. These two algorithms when combined provide a very relevant layer of information for gene expression studies (Microarray, RNA-seq and single-cell RNA-seq data).","tags":[],"title":"CeTF","type":"project"},{"authors":[],"categories":[],"content":"","date":1596971320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596971320,"objectID":"af8ab9a81b963b764ea6260913700d65","permalink":"https://cbiagii.github.io/project/docker/","publishdate":"2020-08-09T13:08:40+02:00","relpermalink":"/project/docker/","section":"project","summary":"Docker repository with images related to analyzes focused on single-cell RNA-seq data, miRNA prediction, etc.","tags":[],"title":"Docker","type":"project"},{"authors":["Codo AC","Davanzo GG","Monteiro LB","de Souza GF","Muraro SP","Virgilio-da-Silva JV","Prodonoff JS","Carregari VC","de Biagi Junior CAO","Crunfli F","Jimenez Restrepo JL","Vendramini PH","Reis-de-Oliveira G","Bispo Dos Santos K","Toledo-Teixeira DA","Parise PL","Martini MC","Marques RE","Carmo HR","Borin A","Coimbra LD","Boldrini VO","Brunetti NS","Vieira AS","Mansour E","Ulaf RG","Bernardes AF","Nunes TA","Ribeiro LC","Palma AC","Agrela MV","Moretti ML","Sposito AC","Pereira FB","Velloso LA","Vinolo MAR","Damasio A","ProenÃ§a-MÃ³dena JL","Carvalho RF","Mori MA","Martins-de-Souza D","Nakaya HI","Farias AS","Moraes-Vieira PM"],"categories":[],"content":"","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"b13bbe30cb28e1348c772cefcd7c0c12","permalink":"https://cbiagii.github.io/publication/covid/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/covid/","section":"publication","summary":"COVID-19 can result in severe lung injury. It remained to be determined why diabetic individuals with uncontrolled glucose levels are more prone to develop the severe form of COVID-19. The molecular mechanism underlying SARS-CoV-2 infection and what determines the onset of the cytokine storm found in severe COVID-19 patients are unknown. Monocytes and macrophages are the most enriched immune cell types in the lungs of COVID-19 patients and appear to have a central role in the pathogenicity of the disease. These cells adapt their metabolism upon infection and become highly glycolytic, which facilitates SARS-CoV-2 replication. The infection triggers mitochondrial ROS production, which induces stabilization of hypoxia-inducible factor-1Î± (HIF-1Î±) and consequently promotes glycolysis. HIF-1Î±-induced changes in monocyte metabolism by SARS-CoV-2 infection directly inhibit T cell response and reduce epithelial cell survival. Targeting HIF-1É‘ may have great therapeutic potential for the development of novel drugs to treat COVID-19.","tags":[],"title":"Elevated Glucose Levels Favor SARS-CoV-2 Infection and Monocyte Response through a HIF-1Î±/Glycolysis-Dependent Axis","type":"publication"},{"authors":null,"categories":null,"content":"Sometimes working with R within an High-Performance Computing (HPC) environment is difficult. If you use an HPC or server that uses the Slurm Workload Manager (SLURM) system for job submission, I will present an alternative that helps me a lot when I need to submit some analysis to the job queue. Let\u0026rsquo;s create a situation here: imagine that you have 5 different single-cell data or 5 samples from different patients, and, starting from the raw count file or the files provided by 10X genomics, you want to pre-process the data using the Seurat standard pipeline.\nFirst, we will have to create a file that here we will call sampleName.txt, which contains the names of the samples. Below is an example of this very simple file:\nsample_01 sample_02 sample_03 sample_04 sample_05  Then a file called SeuratPreProcess.R should be created, which will contain the script with the standard Seurat commands. An example of the script is below:\n#!/usr/bin/env Rscript arguments = commandArgs(trailingOnly=TRUE) options(future.globals.maxSize = 20 * 1024 ^ 3) plan(\u0026quot;multiprocess\u0026quot;, workers = 6) sample \u0026lt;- as.character(arguments) # Loading packages library(Seurat) library(future) # Check if the input is a csv file or a 10x directory test \u0026lt;- dir.exists(file.path(\u0026quot;/path/to/datasets\u0026quot;, sample)) if (test) { data \u0026lt;- CreateSeuratObject(counts = Read10X(data.dir = file.path(\u0026quot;/path/to/datasets\u0026quot;, sample)), project = sample, min.cells = 3, min.features = 200) } else { tmp \u0026lt;- list.files(\u0026quot;/path/to/datasets\u0026quot;, full.names = T) data \u0026lt;- CreateSeuratObject(counts = read.table(grep(sample, tmp, value = T), header = T, row.names = 1), project = sample, min.cells = 3, min.features = 200) } s.genes \u0026lt;- cc.genes$s.genes g2m.genes \u0026lt;- cc.genes$g2m.genes dir.create(file.path(\u0026quot;/path/to/output\u0026quot;, sample)) data[[\u0026quot;percent.mt\u0026quot;]] \u0026lt;- PercentageFeatureSet(data, pattern = \u0026quot;^MT-\u0026quot;) data \u0026lt;- subset(data, subset = nFeature_RNA \u0026lt; 3000 \u0026amp; percent.mt \u0026lt; 10) data \u0026lt;- NormalizeData(data, verbose = F) data \u0026lt;- FindVariableFeatures(data, verbose = F) data \u0026lt;- CellCycleScoring(data, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE) data \u0026lt;- ScaleData(data, vars.to.regress = c(\u0026quot;nCount_RNA\u0026quot;, \u0026quot;percent.mt\u0026quot;, \u0026quot;S.Score\u0026quot;, \u0026quot;G2M.Score\u0026quot;)) data \u0026lt;- RunPCA(data, verbose = F) data \u0026lt;- FindNeighbors(data) data \u0026lt;- FindClusters(data) data \u0026lt;- RunTSNE(data, perplexity = 30, dims = 1:30) data \u0026lt;- RunUMAP(data, dims = 1:30) # Save seurat object saveRDS(data, file = file.path(\u0026quot;/path/to/output\u0026quot;, sample, paste0(sample, \u0026quot;.rds\u0026quot;)))  Here I draw your attention to some details of the script:\n The first line is the shebang line, and the second one indicates that the script will receive the sample name as arguments as input.  #!/usr/bin/env Rscript arguments = commandArgs(trailingOnly=TRUE)  Changes the /path/to/output variable pointing to the directory that contains the sample folders.  The next step is to create a script named submitJob_SeuratPreProcess.R. This script has the function of creating the btc file for the job submission.\nlibrary(optparse) library(digest) option_list = list( make_option(c(\u0026quot;-f\u0026quot;, \u0026quot;--file\u0026quot;), type=\u0026quot;character\u0026quot;, default=NULL, help=\u0026quot;sample names file [default= %default]\u0026quot;, metavar=\u0026quot;character\u0026quot;), make_option(c(\u0026quot;-p\u0026quot;, \u0026quot;--script\u0026quot;), type=\u0026quot;character\u0026quot;, default=NULL, help=\u0026quot;path to script file [default= %default]\u0026quot;, metavar=\u0026quot;character\u0026quot;), make_option(c(\u0026quot;-c\u0026quot;, \u0026quot;--cpu\u0026quot;), type=\u0026quot;numeric\u0026quot;, default=NULL, help=\u0026quot;number of cpus per task [default= %default]\u0026quot;, metavar=\u0026quot;numeric\u0026quot;), make_option(c(\u0026quot;-m\u0026quot;, \u0026quot;--mem\u0026quot;), type=\u0026quot;character\u0026quot;, default=NULL, help=\u0026quot;number of minimum amount of real memory [default= %default]\u0026quot;, metavar=\u0026quot;character\u0026quot;), make_option(c(\u0026quot;-t\u0026quot;, \u0026quot;--time\u0026quot;), type=\u0026quot;numeric\u0026quot;, default=NULL, help=\u0026quot;time limit in minutes [default= %default]\u0026quot;, metavar=\u0026quot;numeric\u0026quot;) ); opt_parser = OptionParser(option_list=option_list); opt = parse_args(opt_parser); if (is.null(opt$file)){ print_help(opt_parser) stop(\u0026quot;Input a sample names file.\u0026quot;, call.=FALSE) } else if (is.null(opt$script)){ print_help(opt_parser) stop(\u0026quot;Input a path to a script file.\u0026quot;, call.=FALSE) } else if (is.null(opt$cpu)) { print_help(opt_parser) stop(\u0026quot;Input the number of cpus per task.\u0026quot;, call.=FALSE) } else if (is.null(opt$mem)) { print_help(opt_parser) stop(\u0026quot;Input the number of minimum amount of real memory.\u0026quot;, call.=FALSE) } else if (is.null(opt$time)) { print_help(opt_parser) stop(\u0026quot;time limit in minutes.\u0026quot;, call.=FALSE) } df \u0026lt;- readLines(opt$file) jobname \u0026lt;- paste0(\u0026quot;tmp_\u0026quot;, digest(Sys.time(), algo = \u0026quot;xxhash32\u0026quot;)) for (i in seq_along(df)) { sink(paste0(\u0026quot;/scratch/biagi/\u0026quot;, jobname, \u0026quot;_\u0026quot;, i, \u0026quot;.btc\u0026quot;)) cat(\u0026quot;#! /bin/bash -l\u0026quot;, \u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;#SBATCH --job-name \u0026quot;, paste0(jobname, \u0026quot;_\u0026quot;, i)), \u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;#SBATCH --error \u0026quot;, paste0(\u0026quot;/scratch/biagi/\u0026quot;, jobname, \u0026quot;_\u0026quot;, i, \u0026quot;.err\u0026quot;)), \u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;#SBATCH --output \u0026quot;, paste0(\u0026quot;/scratch/biagi/\u0026quot;, jobname, \u0026quot;_\u0026quot;, i, \u0026quot;.out\u0026quot;), \u0026quot;\\n\u0026quot;)) cat(paste0(\u0026quot;#SBATCH --cpus-per-task=\u0026quot;, opt$cpu), \u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;#SBATCH --mem=\u0026quot;, opt$mem), \u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;#SBATCH --time=\u0026quot;, opt$time), \u0026quot;\\n\u0026quot;) cat(\u0026quot;\\n\u0026quot;) cat(paste0(\u0026quot;R --vanilla -f \u0026quot;, opt$script, \u0026quot; --args \u0026quot;, df[i]), \u0026quot;\\n\u0026quot;) cat(\u0026quot;\\n\u0026quot;) cat(\u0026quot;echo [$(date)] Starting execution of sample\u0026quot;, \u0026quot;\\n\u0026quot;) sink() system(paste0(\u0026quot;sbatch /scratch/biagi/\u0026quot;, jobname, \u0026quot;_\u0026quot;, i, \u0026quot;.btc\u0026quot;)) }  The above script has the following options:\n -f or \u0026ndash;file: sample name file (for example the previously created file named sampleName.txt); -p or \u0026ndash;script: path to script file (for example the previously created file named SeuratPreProcess.R); -c or \u0026ndash;cpu: number of cpus per task to be used in HPC/server; -m or \u0026ndash;mem: number of minimum amount of real memory to be used in HPC/server; -t ot \u0026ndash;time: time limit in minutes to run the script in HPC/server.  The script will create an random btc and logs files name (xxhash32 algorithm) to save in any chosen directory. I prefer to save in the server\u0026rsquo;s scratch folder, because after a certain time these files are deleted. Remembering that the options in the btc file can be modified in the script, just follow the same pattern as the existing commands.\nFinally, we will gather all the scripts and information generated above, to submit our jobs. Running this command, 5 jobs from the 5 samples of the different patients will be submitted to the queue, and as soon as they have resources they will be run. Submission is very simple, and can be done using the following command:\nRscript --vanilla /path/to/folder/submitJob_SeuratPreProcess.R \\ --file /projects/cangen/coliveir/sampleName.txt \\ --script /projects/cangen/coliveir/scripts/SeuratPreProcess.R \\ --cpu 24 \\ --mem 120G \\ --time 720  Remembering again that this is an application that can be easily customized for any script in R. Each step can be modified according to your needs and the available resources. I hope it may have helped you to understand this integration between R scripts and job submission. It really helps me daily in the analysis and I found it interesting to share. Any questions, comments, suggestions, criticisms, etc., feel free!\nDid you find this page helpful? Consider sharing it ðŸ™Œ ","date":1593388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593388800,"objectID":"2b370986de14279992c5248078b182e1","permalink":"https://cbiagii.github.io/post/post_03/","publishdate":"2020-06-29T00:00:00Z","relpermalink":"/post/post_03/","section":"post","summary":"Sometimes working with R within an High-Performance Computing (HPC) environment is difficult. If you use an HPC or server that uses the Slurm Workload Manager (SLURM) system for job submission, I will present an alternative that helps me a lot when I need to submit some analysis to the job queue.","tags":["R","SLURM","script"],"title":"Integrating R with SLURM job submission","type":"post"},{"authors":null,"categories":null,"content":"This post is about a big question in single-cell analysis: how to classify/identify the cell types of my data? I would like to have an answer, but there is still no consensus. According to the scRNA-tools website, there are 67 cataloged tools for classifying cell types implemented in R, Python, etc. I consider that there are two main types of classifying cell types:\n Using classic known markers, as PECAM1 for Edothelial cells, CD19 for B cells, etc. A website that has a very extensive and complete database is CellMarker, where you can find genes marker based on the literature and experiments. This classification of cell types is based on the high expression of these specific marker genes. Using automated methods that infers the cell type. As stated above, you can find a list of these different tools on the scRNA-tools website.  The most common way of doing the classification is by identifying the different clusters and doing differential expression analysis of one group against all the others in order to find the genes that are most differentially expressed in each group. In this post I chose to talk to you about a very interesting tool that combines this principle mentioned above with a database of markers for different tissues and cancers. The tool is called scCATCH and the original article can be found here and with the GitHub page. An overview of the package is show in Figure 1 below.\nFig. 1: Overview of scCATCH (image taken from the original article.)\nThe tool is implemented as an R package and includes a panel of 353 cell types and related 686 subtypes associated with 184 tissue types, 20,792 cell-specific marker genes and 2,097 references of human and mouse. More informations about the package can be found in the GitHub and paper mentioned above. \u0026ldquo;Basically\u0026rdquo;, the package will find the marker genes for each cluster and associate those genes with the database.\nOne of the strategies used in this tool that caught my attention was that instead of calculating the markers for a specific cluster comparing against all the others, it calculates the markers of that cluster against each one individually and joining these information at the end. I tried to implement the tool on some data that I am analyzing but I realized that it was taking a long time to run (approximately 5h for a total of 10k cells with 18 clusters). So I decided to take a closer look at the source code and found that piece of code:\nFig. 2: Step in which the markers for each cluster are calculated.\nIn summary, this part of the code will calculate the logFC, pvalue using the Wilcox test and the percentage of expression of a specific marker between two clusters. These steps are very time-consuming because are implemented in R, and calculates the Wilcox test for each case. To solve this first I looked for a parallelization parameter in the package, but it is not implemented in the package.\nSo to continue using scCATCH more efficiently I edited the source code of the part above (Fig. 2) as shown in Fig. 3:\nFig. 3: Piece of code modified.\nThe implementation I did is to keep the same calculations, but now using the FindMarkers function of the Seurat package to perform the Wilcox test and get the pvalue, in addition to calculating the percentage of expression of a specific marker between two clusters. The logFC calculation was maintained as proposed in scCATCH package.\nThe package with these modifications can be downloaded here and installed using de following command:\ninstall.packages(\u0026quot;/path/to/package/scCATCH_2.0.tar.gz\u0026quot;, repos = NULL)  Why/How will this implementation improve the scCATCH performance? There is an R package called Future that provides a lightweight and unified Future API for sequential and parallel processing of R expression. The Seurat package has a tutorial that shows you how to perform parallelization in Seurat with future, and one of the functions that are enabled for parallelization using the future package is FindMarkers, exactly the one I used in the implementation above. With Future is possible to plan differents strategies to parallelize the scCATCH package, like sequential, multisession, multicore, multiprocess, clusters, etc. A more detailed explanation of the plan types can be found in the package vignette.\nSo, one example of the way of using the Future package along with scCATCH is that way:\n# Loading packages library(Seurat) library(future) library(scCATCH) # Set memory for each worker options(future.globals.maxSize = 1000 * 1024^2) # An example with multicore planning 10 workers plan(\u0026quot;multicore\u0026quot;, workers = 10) # Running scCATCH as default showed in their GitHub page clu_markers \u0026lt;- findmarkergenes(object = data, species = 'Human', cluster = 'All', match_CellMatch = FALSE, cancer = NULL, tissue = NULL, cell_min_pct = 0.25, logfc = 0.25, pvalue = 0.05) clu_ann \u0026lt;- scCATCH(object = clu_markers$clu_markers, species = 'Human', tissue = \u0026quot;Pancreas\u0026quot;)  This is very impressive because in the same dataset without this modification that was taking approximately 5 hours it is now taking less than 10 minutes, with the same satisfactory results!!\nFinally, the result of the scCATCH function is the classification of cell types for different clusters. I realized that for the results of my data there were 2 clusters that the tool had not been able to classify, so when translating these results to Seurat in order to obtain a graphical visualization (tSNE or UMAP), the assignment of the clusters with the cell types were wrong or out of order. From there, I created a function that takes the dataframe resulting from the scCATCH function, along with the Seurat object with the data, and automatically adds the classification information, placing as clusters that have not been classified as unclassified.\nThe function is as follows:\nconvertSeurat \u0026lt;- function(seurat_object, scCATCH_anno) { tmp1 \u0026lt;- data.frame(cluster = levels(Idents(seurat_object))) tmp \u0026lt;- merge(tmp1, scCATCH_anno, by = 'cluster', all = T) tmp$cell_type[which(is.na(tmp$cell_type))] \u0026lt;- \u0026quot;Unclassified\u0026quot; new.cluster.ids \u0026lt;- tmp$cell_type names(new.cluster.ids) \u0026lt;- levels(seurat_object) seurat_object \u0026lt;- RenameIdents(seurat_object, new.cluster.ids) return(seurat_object) } # data is the Seurat object and clu_ann the scCATCH result data \u0026lt;- convertSeurat(data, clu_ann)  That\u0026rsquo;s all for today, folks! I hope it was a good introduction to the subject of classifying cell types applied to single-cell data. As stated at the beginning, this subject is very broad, and my intention was to give an overview of a tool that I found very interesting for this function with a smart modification for better performance. As is known, manual classification classification is usually time-consuming, that way having tools that can automatically classify can save time and resources!\nI hope it may have helped you to understand a little this whole process, and mainly that with this function it may have facilitated the use of the SCCAF tool. Any questions, comments, suggestions, criticisms, etc., feel free!\nDid you find this page helpful? Consider sharing it ðŸ™Œ ","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591920000,"objectID":"d962100a2776e3e8f8bdc53e5c669e6a","permalink":"https://cbiagii.github.io/post/post_02/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/post/post_02/","section":"post","summary":"This post is about a big question in single-cell analysis: how to classify/identify the cell types of my data? I would like to have an answer, but there is still no consensus.","tags":["single-cell","R","cell type","classify","parallel","scCATCH","Seurat"],"title":"A fast and smart alternative for classifying cell types","type":"post"},{"authors":null,"categories":null,"content":"I had been analyzing the data for a while with my friend Cleidson and we always asked ourselves, how to determine the optimal number of clusters for our data? I think this is one of the main questions when working with single-cell data. Although some better known tools like Seurat (R) and Scanpy (Python) have different methods of clustering, they do not return the optimal number of clusters. What I had been doing previously was generating different resolutions with the data and checking with the clustree package in R how the clusters were split from the smallest to the maximum resolution that I had predetermined.\nI was generating something like this:\ndata \u0026lt;- FindClusters(data, resolution = seq(0, 1, 0.1)) clustree(data)  Fig. 1: clustree visualization.\nThe approach was basically to look at the graph above and identify the resolution where there were not many changes in the numbers of clusters. It is not the best alternative by far, but it was an attempt.\nUntil following on Twitter I saw a paper that came out on May 18th, and I found the methodology and results very interesting. The paper included the SCCAF tool(installation instructions) which, in simple words, assumes that you pass as input each cluster being theoretically a cell type, and from the implementation of SCCAF (which includes a good part of machine learning) will return what is the combination of clusters (or cell types) that have better accuracy. Are you confused yet? I\u0026rsquo;ll show you an example below.\nThe tool was made entirely in Python, and I had my data all run using Seurat, in R. Initially I thought that a simple conversion of the seurat object to a loom file would be enough, but I had the following problem when putting SCCAF to run:\nimport warnings warnings.filterwarnings(\u0026quot;ignore\u0026quot;) from SCCAF import * ad = sc.read(filename=\u0026quot;/projects/biagi/data.loom\u0026quot;) ad.obs['L1_Round0'] = ad.obs['clusters'] SCCAF_optimize_all(min_acc=0.953, ad=ad, basis ='tsne', c_iter=5)  Fig. 2: SCCAF error message.\nI realized that the way that Seurat generates the loom file was not the default way for the AnnData object that will be read inside python. To work around this problem, I tested numerous alternatives, but none worked. Then I remembered that in version 2 of Seurat there was a function that converted the seurat object to a h5ad file. So I took the source function of version 2 as a base and went on adapting and modifying it until I had a function that converts the seurat object to an h5ad file, which is exactly what we need to give as input to SCCAF.\nSeuratToH5ad \u0026lt;- function(seurat_object, filename, assay = NULL, res = 1) { library(reticulate) if (!py_module_available(\u0026quot;anndata\u0026quot;) | !py_module_available(\u0026quot;scanpy\u0026quot;) | !py_module_available(\u0026quot;igraph\u0026quot;) | !py_module_available(\u0026quot;louvain\u0026quot;)) { stop(\u0026quot;Please install the anndata python module\u0026quot;) } ad \u0026lt;- import(\u0026quot;anndata\u0026quot;) sc \u0026lt;- import(\u0026quot;scanpy\u0026quot;) message(paste(\u0026quot;Starting to fix the mess...\u0026quot;)) raw \u0026lt;- seurat_object@assays$RNA@data if (assay == \u0026quot;RNA\u0026quot;) { X \u0026lt;- seurat_object@assays$RNA@scale.data } else if (assay == \u0026quot;SCT\u0026quot;) { X \u0026lt;- seurat_object@assays$SCT@scale.data } else { stop(\u0026quot;Please select an existent assay\u0026quot;) } cell_names \u0026lt;- colnames(x = X) gene_names \u0026lt;- rownames(x = X) raw \u0026lt;- as(object = raw, Class = \u0026quot;dgCMatrix\u0026quot;) scipy \u0026lt;- import(module = 'scipy.sparse', convert = FALSE) sp_sparse_csc \u0026lt;- scipy$csc_matrix raw.rownames \u0026lt;- rownames(x = raw) raw \u0026lt;- sp_sparse_csc( tuple(np_array(raw@x), np_array(raw@i), np_array(raw@p)), shape = tuple(raw@Dim[1], raw@Dim[2]) ) raw \u0026lt;- raw$T raw \u0026lt;- dict(X = raw, var = dict(var_names = raw.rownames)) X \u0026lt;- np_array(t(x = X)) obsm \u0026lt;- list() for (dr in names(seurat_object@reductions)) { obsm[[paste0(\u0026quot;X_\u0026quot;,dr)]] \u0026lt;- np_array(Embeddings( object = seurat_object, reduction = dr )) } obsm \u0026lt;- dict(obsm) meta_data \u0026lt;- seurat_object@meta.data if (\u0026quot;nCount_RNA\u0026quot; %in% colnames(x = meta_data)) { colnames(x = meta_data) \u0026lt;- gsub( pattern = \u0026quot;nCount_RNA\u0026quot;, replacement = \u0026quot;n_counts\u0026quot;, x = colnames(x = meta_data) ) } if (\u0026quot;nFeature_RNA\u0026quot; %in% colnames(x = meta_data)) { colnames(x = meta_data) \u0026lt;- gsub( pattern = \u0026quot;nFeature_RNA\u0026quot;, replacement = \u0026quot;n_genes\u0026quot;, x = colnames(x = meta_data) ) } colnames(x = meta_data) \u0026lt;- gsub( pattern = \u0026quot;\\\\.\u0026quot;, replacement = \u0026quot;_\u0026quot;, x = colnames(x = meta_data) ) anndata.object \u0026lt;- ad$AnnData( raw = raw, X = X, obs = meta_data, obsm = obsm ) anndata.object$var_names \u0026lt;- gene_names anndata.object$obs_names \u0026lt;- cell_names message(paste(\u0026quot;Clustering for resolution:\u0026quot;, res)) sc$pp$neighbors(anndata.object) sc$tl$louvain(anndata.object, resolution=res, key_added = paste0(\u0026quot;res\u0026quot;, res)) message(paste(\u0026quot;Writing to h5ad file...\u0026quot;)) anndata.object$write(filename) message(paste(\u0026quot;Finished!!\u0026quot;)) }  Let\u0026rsquo;s explain in more detail the function parameters:\n seurat_object: a seurat object with the basic steps already run (NormalizeData, FindVariableFeatures, ScaleData, RunPCA, FindNeighbors, FindClusters and RunUMAP/RunTSNE); filename: path with file name (i.e. /path/to/output/file.h5ad); assay: choose between RNA or SCT; res: resolution for clustering if clustering has not yet been done.  So, in the end the function will bem implemented this way:\nSeuratToH5ad(seurat_object = data, filename = \u0026quot;/path/to/output//data.h5ad\u0026quot;, assay = \u0026quot;RNA\u0026quot;, res = 1)  Some important details: for the function to work it is necessary to have the reticulate package installed. In addition to it, it is necessary to install the anndata, scanpy, pandas, louvain modules in the r-reticulate environment that the Seurat package itself creates automatically.\nTo install these modules, simply identify the full name of the r-reticulate environment:\n# list all available conda environments conda env list # in my case conda activate /home/biagi/.local/share/r-miniconda/envs/r-reticulate # installing each module manually conda install -c bioconda anndata conda install -c bioconda scanpy conda install -c anaconda pandas conda install -c conda-forge louvain # deactivate r-reticulate env conda deactivate  The next steps, from the generated h5ad file, can be followed through the tutorial available on the tool\u0026rsquo;s GitHub.\nI ran for a dataset with approximately 70,000 cells and the complete SCCAF analysis took almost 2 hours. Consider that I am using the Cologne High Efficiency Operating Platform for Science (CHEOPS).\nI strongly recommend reading the original paper before using the tool to better understand the methods. As I said at the beginning, I used it in my data and the results were very satisfactory and I included it in the default pipeline of my analyzes.\nI hope it may have helped you to understand a little this whole process, and mainly that with this function it may have facilitated the use of the SCCAF tool. Any questions, comments, suggestions, criticisms, etc., feel free!\nDid you find this page helpful? Consider sharing it ðŸ™Œ ","date":1590278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590278400,"objectID":"5841e13cca8cfa3724bc41483dcf34d8","permalink":"https://cbiagii.github.io/post/post_01/","publishdate":"2020-05-24T00:00:00Z","relpermalink":"/post/post_01/","section":"post","summary":"I had been analyzing the data for a while with my friend Cleidson and we always asked ourselves, how to determine the optimal number of clusters for our data? I think this is one of the main questions when working with single-cell data.","tags":["single-cell","R","python","clustering","Seurat","SCCAF"],"title":"Stop your analysis until you read this clustering secret","type":"post"},{"authors":["Carlos Alberto Oliveira de Biagi Jr","Ricardo Perecin Nociti","Breno Osvaldo Funicheli","PatrÃ­cia de CÃ¡ssia Ruy","JoÃ£o Paulo Bianchi Ximenez","Wilson AraÃºjo Silva Jr"],"categories":[],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"f30618389ef4db18598a725c01916b2c","permalink":"https://cbiagii.github.io/publication/cetf/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/cetf/","section":"publication","summary":"Finding meaningful gene-gene associations and the main Transcription Factors (TFs) in co-expression networks is one of the most important challenges in gene expression data mining. CeTF is an R package that integrates the Partial Correlation with Information Theory (PCIT) and Regulatory Impact Factors (RIF) algorithms applied to gene expression data from microarray, RNA-seq, or single-cell RNA-seq platforms. This approach allows identifying the transcription factors most likely to regulate a given network in different biological systems â€” for example, regulation of gene pathways in tumor stromal cells and tumor cells of the same tumor. This pipeline can be easily integrated into the high-throughput analysis.","tags":[],"title":"CeTF: an R package to Coexpression for Transcription Factors using Regulatory Impact Factors (RIF) and Partial Correlation and Information (PCIT) analysis","type":"publication"},{"authors":["das Chagas PF","de Sousa GR","Kodama MH","de Biagi Junior CAO","Yunes JA","Brandalise SR","Calin GA","Tone LG","Scrideli CA","de Oliveira JC"],"categories":[],"content":"","date":1580342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580342400,"objectID":"e1f69ec56f69141c822d4a2547669242","permalink":"https://cbiagii.github.io/publication/ultraconserved/","publishdate":"2020-01-30T00:00:00Z","relpermalink":"/publication/ultraconserved/","section":"publication","summary":"Aberrant expression of long non-coding RNAs (lncRNAs) has been detected in several types of cancer, including acute lymphoblastic leukemia (ALL), but lncRNA mapped on transcribed ultraconserved regions (T-UCRs) are little explored. The T-UCRs uc.112, uc.122, uc.160 and uc.262 were evaluated by quantitative real-time PCR in bone marrow samples from children with T-ALL (n=32) and common-ALL/pre-B ALL (n=30). In pediatric ALL, higher expression levels of uc.112 were found in patients with T-ALL, compared to patients with B-ALL. T-cells did not differ significantly from B-cells regarding uc.112 expression in non-tumor precursors from public data. Additionally, among B-ALL patients, uc.112 was also found to be increased in patients with hyperdiploidy, compared to other karyotype results. The uc.122, uc.160, and uc.262 were not associated with biological or clinical features. These findings suggest a potential role of uc.112 in pediatric ALL and emphasize the need for further investigation of T-UCR in pediatric ALL.","tags":[],"title":"Ultraconserved long non-coding RNA uc.112 is highly expressed in childhood T versus B-cell acute lymphoblastic leukemia","type":"publication"},{"authors":["Siena ÃDD","PlaÃ§a JR","AraÃºjo LF","de Barros II","Peronni K","Molfetta G","de Biagi CAO Jr","Espreafico EM","Sousa JF","Silva WA Jr"],"categories":[],"content":"","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"d7820d42238c9367a563d30bbe432773","permalink":"https://cbiagii.github.io/publication/zeb1/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/zeb1/","section":"publication","summary":"Melanoma is the deadliest form of skin cancer, and little is known about the impact of deregulated expression of long noncoding RNAs (lncRNAs) in the progression of this cancer. In this study, we explored RNA-Seq data to search for lncRNAs associated with melanoma progression. We found distinct lncRNA gene expression patterns across melanocytes, primary and metastatic melanoma cells. Also, we observed upregulation of the lncRNA ZEB1-AS1 (ZEB1 antisense RNA 1) in melanoma cell lines. Data analysis from The Cancer Genome Atlas (TCGA) confirmed higher ZEB1-AS1 expression in metastatic melanoma and its association with hotspot mutations in BRAF (B-Raf proto-oncogene, serine/threonine kinase) gene and RAS family genes. In addition, a positive correlation between ZEB1-AS1 and ZEB1 (zinc finger E-box binding homeobox 1) gene expression was verified in primary and metastatic melanomas. Using gene expression signatures indicative of invasive or proliferative phenotypes, we found an association between ZEB1-AS1 upregulation and a transcriptional profile for invasiveness. Enrichment analysis of correlated genes demonstrated cancer genes and pathways associated with ZEB1-AS1. We suggest that the lncRNA ZEB1-AS1 could function by activating ZEB1 gene expression, thereby influencing invasiveness and phenotype switching in melanoma, an epithelial-to-mesenchymal transition (EMT)-like process, which the ZEB1 gene has an essential role.","tags":[],"title":"Whole transcriptome analysis reveals correlation of long noncoding RNA ZEB1-AS1 with invasive profile in melanoma","type":"publication"},{"authors":["Cruzeiro GAV","SalomÃ£o KB","de Biagi CAO Jr","Baumgartner M","Sturm D","Lira RCP","de Almeida MagalhÃ£es T","Baroni Milan M","da Silva Silveira V","Saggioro FP","de Oliveira RS","Dos Santos Klinger PH","Seidinger AL","Yunes JA","de Paula Queiroz RG","Oba-Shinjo SM","Scrideli CA","Nagahashi SMK","Tone LG","Valera ET"],"categories":[],"content":"","date":1554336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554336000,"objectID":"557ef8a280608405745c80ab386da61a","permalink":"https://cbiagii.github.io/publication/medulloblastoma/","publishdate":"2019-04-04T00:00:00Z","relpermalink":"/publication/medulloblastoma/","section":"publication","summary":"Next-generation sequencing platforms are routinely used for molecular assignment due to their high impact for risk stratification and prognosis in medulloblastomas. Yet, low and middle-income countries still lack an accurate cost-effective platform to perform this allocation. TaqMan Low Density array (TLDA) assay was performed using a set of 20 genes in 92 medulloblastoma samples. The same methodology was assessed in silico using microarray data for 763 medulloblastoma samples from the GSE85217 study, which performed MB classification by a robust integrative method (Transcriptional, Methylation and cytogenetic profile). Furthermore, we validated in 11 MBs samples our proposed method by Methylation Array 450 K to assess methylation profile along with 390 MB samples (GSE109381) and copy number variations. TLDA with only 20 genes accurately assigned MB samples into WNT, SHH, Group 3 and Group 4 using Pearson distance with the average-linkage algorithm and showed concordance with molecular assignment provided by Methylation Array 450 k. Similarly, we tested this simplified set of gene signatures in 763 MB samples and we were able to recapitulate molecular assignment with an accuracy of 99.1% (SHH), 94.29% (WNT), 92.36% (Group 3) and 95.40% (Group 4), against 97.31, 97.14, 88.89 and 97.24% (respectively) with the Ward.D2 algorithm. t-SNE analysis revealed a high level of concordance (k = 4) with minor overlapping features between Group 3 and Group 4. Finally, we condensed the number of genes to 6 without significantly losing accuracy in classifying samples into SHH, WNT and non-SHH/non-WNT subgroups. Additionally, we found a relatively high frequency of WNT subgroup in our cohort, which requires further epidemiological studies. TLDA is a rapid, simple and cost-effective assay for classifying MB in low/middle income countries. A simplified method using six genes and restricting the final stratification into SHH, WNT and non-SHH/non-WNT appears to be a very interesting approach for rapid clinical decision-making.","tags":[],"title":"A simplified approach using Taqman low-density array for medulloblastoma subgrouping","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://cbiagii.github.io/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"Hello!","tags":null,"title":"Projects","type":"widget_page"},{"authors":["Araujo LF","Siena ADD","PlaÃ§a JR","Brotto DB","Barros II","Muys BR","Biagi CAO Jr","Peronni KC","Sousa JF","Molfetta GA","West LC","West AP","Leopoldino AM","Espreafico EM","Silva WA Jr"],"categories":[],"content":"","date":1537488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537488000,"objectID":"7f135165b0021bc3de9f6456b4ccc733","permalink":"https://cbiagii.github.io/publication/tfam/","publishdate":"2018-09-21T00:00:00Z","relpermalink":"/publication/tfam/","section":"publication","summary":"Mitochondria are central key players in cell metabolism, and mitochondrial DNA (mtDNA) instability has been linked to metabolic changes that contribute to tumorigenesis and to increased expression of pro-tumorigenic genes. Here, we use melanoma cell lines and metastatic melanoma tumors to evaluate the effect of mtDNA alterations and the expression of the mtDNA packaging factor, TFAM, on energetic metabolism and pro-tumorigenic nuclear gene expression changes. We report a positive correlation between mtDNA copy number, glucose consumption, and ATP production in melanoma cell lines. Gene expression analysis reveals a down-regulation of glycolytic enzymes in cell lines and an up-regulation of amino acid metabolism enzymes in melanoma tumors, suggesting that TFAM may shift melanoma fuel utilization from glycolysis towards amino acid metabolism, especially glutamine. Indeed, proliferation assays reveal that TFAM-down melanoma cell lines display a growth arrest in glutamine-free media, emphasizing that these cells rely more on glutamine metabolism than glycolysis. Finally, our data indicate that TFAM correlates to VEGF expression and may contribute to tumorigenesis by triggering a more invasive gene expression signature. Our findings contribute to the understanding of how TFAM affects melanoma cell metabolism, and they provide new insight into the mechanisms by which TFAM and mtDNA copy number influence melanoma tumorigenesis.","tags":[],"title":"Mitochondrial transcription factor A (TFAM) shapes metabolic and invasion gene signatures in melanoma","type":"publication"}]